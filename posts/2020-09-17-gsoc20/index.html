<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Google Summer of Code 2020 | mzfr's Blog</title>
<meta name=keywords content="GSoC">
<meta name=description content="This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for which I&rsquo;ve been trying to get selected from past 2 years.
Background I got to know about Google Summer of Code back in 2018, when I learned that my elder brother has done it 3 years in a row.">
<meta name=author content>
<link rel=canonical href=https://blog.mzfr.me/posts/2020-09-17-gsoc20/>
<link href=https://blog.mzfr.me/assets/css/stylesheet.min.71a045fe4a2a5bf34f40205ef5e9930aa6d0121635632bf5e9d17a442a8e8d1e.css integrity="sha256-caBF/koqW/NPQCBe9emTCqbQEhY1Yyv16dF6RCqOjR4=" rel="preload stylesheet" as=style>
<link rel=icon href=https://blog.mzfr.me/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://blog.mzfr.me/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://blog.mzfr.me/favicon-32x32.png>
<link rel=apple-touch-icon href=https://blog.mzfr.me/apple-touch-icon.png>
<link rel=mask-icon href=https://blog.mzfr.me/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.91.2">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/monokai-sublime.min.css integrity="sha512-/l4iViNMhxR5MhSlak3Yw/L/7qUBifVy7MpLjeJTc8BPMRFbGplGN0xqufCDwhSdxSnVgy+e/OYsNnU75K3yyQ==" crossorigin=anonymous referrerpolicy=no-referrer>
<script data-ad-client=ca-pub-1450519482686010 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-147356794-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<meta property="og:title" content="Google Summer of Code 2020">
<meta property="og:description" content="This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for which I&rsquo;ve been trying to get selected from past 2 years.
Background I got to know about Google Summer of Code back in 2018, when I learned that my elder brother has done it 3 years in a row.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blog.mzfr.me/posts/2020-09-17-gsoc20/">
<meta property="article:published_time" content="2020-09-18T00:00:00+00:00">
<meta property="article:modified_time" content="2020-09-18T00:00:00+00:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Google Summer of Code 2020">
<meta name=twitter:description content="This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for which I&rsquo;ve been trying to get selected from past 2 years.
Background I got to know about Google Summer of Code back in 2018, when I learned that my elder brother has done it 3 years in a row.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Google Summer of Code 2020","name":"Google Summer of Code 2020","description":"This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for ‚Ä¶","keywords":["GSoC"],"articleBody":"This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for which I‚Äôve been trying to get selected from past 2 years.\nBackground I got to know about Google Summer of Code back in 2018, when I learned that my elder brother has done it 3 years in a row. He wanted me to try to get selected for any org that I like. So I started looking for projects on GSoC archives and came across the Honeynet Project org. I was interested in it because I really liked all the projects under it, projects like Snare\u0026Tanner, Thug, etc. I think these projects attracted my attention because they have a feel of being related to the Information Security field.\nIn GSoC 2018 I submitted 2 proposals, one for Snare \u0026 Tanner under Honeynet Project and another one for a tool called Addon-Checker under XBMC Foundation. I wasn‚Äôt selected for Snare \u0026 Tanner that year but got selected for another project. You can read the blog post about it here\nIn GSoC 2019, I again applied for a project called Cowrie under Honeynet Project and wasn‚Äôt selected. I think it was because the other applicant, who got selected had a slightly better proposal then I did.\nIn 2020, I decided to start early and make some more contributions to Snare \u0026 Tanner. Also, I spent quite some time understanding the exact work required and make a good proposal for it. The mentor of the project was very helpful from the very beginning. She reviewed my proposal twice or thrice before I made a final proposal submission on the GSoC portal\nProposed Work The work that I proposed in my GSoC proposal was:\n Adding support for persistent storage for sessions, in TANNER. Improving cloning and storing functionality of SNARE. Small works like adding a new injection template, using async FTP library etc.  Coding Period I started to work before the official coding begins period, even though I didn‚Äôt write any code but I started to discuss everything with my mentor like what we should do first, how we should start etc. Our initial idea was to start with the most important task which was to add support for PostgreSQL so the storage capability of TANNER, can become a bit more stable. In the early discussion, we decided to add PostgreSQL as an optional DB meaning users will have the option to choose between PostgreSQL and Redis DB. But later we came to the conclusion that it would be nice if we can use the combination of both the databases to improve the overall storage functionality.\nWork Detail Currently, in TANNER, the only way to store all the session data (analyzed and unanalyzed) was to keep it within the Redis. In TANNER the unanalyzed sessions data is the unprocessed data that is sent by the SNARE and it contains information like time of the session, user agent, etc. And analyzed sessions are those which TANNER generates after processing the unanalyzed data. The analyzed data contains information like possible owners i.e whether the sessions were created by a normal user or a crawler/tool, type of attacks, etc\nBack in 2016 when new features were being added to TANNER, Redis was selected as the best choice because of the speed that it offers. Redis provides its speed functionality by storing data in the memory instead of keeping it in the disk. It‚Äôs kind of similar to how a cache of any system works.\nAs the project grew we started to gather more and more data and storing everything in Redis caused it to consume a lot of memory which resulted in unexpected crashes on low spec systems.\nBelow is the diagram which explains how the SNARE \u0026 TANNER is working with the only Redis:\nDisadvantages of this setup\nAs mentioned above higher consumption of memory on a low spec system would result in an unexpected crash of TANNER server. Also, higher memory consumption would cause other memory issues like slowing down other applications present on the system.\nThe Solution\nFirst, we decided that we can add support for Postgres, and then we‚Äôll give users the option to run tanner either with Redis or with Postgres. But later after some discussion, we decided that we‚Äôll use a combination of Redis and Postgres.\nThe way we decided to use them can be seen in the following diagram:\nAs it‚Äôs clear from the above diagram that after analysis we are storing the data in the Postgres and then we are deleting the analyzed data from Redis.\nThe advantages of using the combination of both Postgres and Redis are\n  When TANNER receives a session from SNARE it will be able to store that session data in Redis with much higher speed.\n  Once the session is analyzed then it can be stored in persistent disk storage like Postgres.\n  Change in Data format\nOne of the major advantages of having Postgres as the storage is because it gives us the power to perform queries before presenting that data to the user.\nTANNER API is used to access the data stored in the DB. Let‚Äôs take an example to understand how the API has changed now, we have an endpoint /snare-stats/which returns stats like Number of attacks, total sessions, etc of a given snare instance.\nNow in the old (Only Redis) setup, we were extracting all the data from the DB, and then we were selecting only those keys that were required for that endpoint. But now with the new (Redis+Postgres) setup, we don‚Äôt extract all the data. What we do is we run SQL queries on the data before actually extracting the data, this saves us from unnecessary processing.\nIf you‚Äôd like to see the queries we are executing then please check out the code here\nDetail about the format\nWe decided to store all the data in 4 tables named sessions, cookies, owners, paths. Below you can see the schema of all the tables:\nIf you‚Äôd like to see the initial discussion about this format then check out this small gist that I made.\n Initially, our plan was that I‚Äôll spend around 2 months working on this task, and then in the last month I‚Äôll work on all the other tasks that I proposed but little did we know that adding support for another DB wouldn‚Äôt be as easy as we thought.\nProblems Faced  Finding and fixing a weird bug: I think this was the most frustrating bug that I came across during the whole GSoC time period. So we have 4 tables to in our Postgres DB and out of this there is one main tabled called sessions and then there are other like cookies, owners, and paths. The Sessions data store a kind of reference to these tables and the bug was that when you looked at the data in the sessions table it showed there was data in the other tables but when you look at those tables separately the data was missing out. Example:  a1894717-bf39-4f67-8493-66debde31e0b | 776edef4-ec5f-4fe0-8485-02cf9ff1f64d | 51.158.118.90 | 43972 | France | FR | Paris | 75001 | Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36 | 2020-06-23 20:09:01 | 2020-06-23 20:16:23 | 9.010287049751257 | 0.11098427662381329 | 3983 | 0 | 0 |\rIn this, the number 3983 is the accepted_path value which basically means how many paths a bot/attacker tried in one session. But if we checked the count in the paths table it showed 6\nselect count(*) from paths where session_id='a1894717-bf39-4f67-8493-66debde31e0b'; count -------  6 The issue was that while we moved the session data between Redis(storing the initial data) and Postgres(storing analyzed sessions) some sessions were missing an attack_type. And all this was a fault of a small function called set_attack_type and it was because we were doing some URL encoding while taking information from SNARE to Redis but wasn‚Äôt doing the same after analyzing the data and sending it to POSTGRES.\n Support multiple filters in API: The API as well as the Web application needed to support the multiple filters same time. So say if you want all the sessions from two different IP addresses the API call would look like:  /sessions?filters=ip:127.0.0.1 ip:192.1.1.1\rNow this looks easy and a lot of python devs might see this and be like oh you can split it on space and then it's all easy but it wasn‚Äôt that easy. I had to make sure that no unknown filters were passed and the biggest issue was that I had to generate a SQL query based on all the filters so it(API) can get the exact data out of the DB.\n  Testing: I think this is one of the most important things that I have learned this GSoC. Testing your code is very important and I kind of already knew this but I wasn‚Äôt doing this practically. But a lot of times I felt that I could have caught certain bugs right when they appeared if I had written the test cases for the newly written code right after finishing the code. The problem that I faced during the testing phase exactly ‚Äúwhile writing them‚Äù but it was while running them. Once Pytest would finish running the tests it would show warnings about ‚Äúunclosed connection‚Äù. Fixing this was a bit difficult because most of the libraries used in this project are async and I was quite confused with the working. The most difficult part was that sometimes when I locally ran the tests there were no warnings but in the Travis logs, we could see ike 5-10 warnings so it was hard testing it locally.\n  Shift to SQLAlchemy: This wasn‚Äôt the problem but I am writing about this because this definitely took some of our time. So in the starting I and my mentor thought that using raw SQL queries wouldn‚Äôt be as such of an issue. But once I made some intial changes we both felt that the code was getting a bit dirty and hard to understand. So we decided it would be better if we use SQLAlchemy, since this ORM would provide lot of functionality which would keep our code clean and simple.\n  Completed Work So out of the suggested task, I was able to finish the task of adding support for persistent storage and the other small task like adding new template injections or updating the FTP support to use the async library. Even though I had completed the PostgreSQL task in around 2.5 months and could have tried to do another big task but then my mentor suggested that instead of trying to have a lot of new features, it would be better to improve the existing features that we have. That is why we decided not to go ahead with ‚Äúchanging the snare storage and cloning functionality‚Äù and decided to do other small tasks.\nLesson Learned   It‚Äôs very important to test your code. You can use whatever automated tools possible to try and test them. Also once you feel that you are done adding a new feature, write the tests for the code right away.\n  During the Proposal making phase I had written things like ‚ÄúTake test coverage to 100%‚Äù and ‚Äúfinish PostgreSQL integration in 2 weeks‚Äù but in reality, the DB integration took around ~2.5 months and the test coverage is at around 78% now üòÖ. So after the GSoC I have realized that it‚Äôs better to have few tasks in your timeline with clear deliverables, goals, etc rather than trying to add loads of tas without thinking them through.\n  Sometimes everything is right in front of you you just need to take a good look. This happened with me multiple times, the bug was right in front of me but I still had to ask my mentor about it.\n  Before this I had never worked on any DB related work. I mean I did studied DBMS in my 3rd year of college but never got a chance to work on a real world project so I learned a lot about PostgreSQL, Redis, SQLAlchemy etc.\n  Final thoughts I had planned that even after the GSoC ends I‚Äôll continue to work on the project but due to this year being the final year of my degree my life has changed a lot. Campus placement has started in my college so now I have to prepare for the tests and interviews. Along with that, I have to prepare my thesis and a major project. So right now I am not sure when I‚Äôll get back to contributing to the project.\nIn the end, I just want to thank the Honeynet Project org and my mentor for seeing the potential in me and selecting me for this year GSoC. Also other special thanks to the mentor for being so helpful and patient with me.\n","wordCount":"2157","inLanguage":"en","datePublished":"2020-09-18T00:00:00Z","dateModified":"2020-09-18T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.mzfr.me/posts/2020-09-17-gsoc20/"},"publisher":{"@type":"Organization","name":"mzfr's Blog","logo":{"@type":"ImageObject","url":"https://blog.mzfr.me/favicon.ico"}}}</script>
</head>
<body>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<noscript>
<style type=text/css>.theme-toggle,.top-link{display:none}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://blog.mzfr.me accesskey=h>mzfr's Blog</a>
<span class=logo-switches>
<span class=theme-toggle>
<a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a>
</span>
</span>
</div>
<ul class=menu id=menu onscroll=menu_on_scroll()>
<li>
<a href=https://blog.mzfr.me/>
<span>
Home
</span>
</a>
</li>
<li>
<a href=https://blog.mzfr.me/about/>
<span>
About
</span>
</a>
</li>
<li>
<a href=https://github.com/mzfr/notes/wiki/>
<span>
Notes
</span>
</a>
</li>
<li>
<a href=https://blog.mzfr.me/ctf/>
<span>
Writeups
</span>
</a>
</li></ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Google Summer of Code 2020
</h1>
<div class=post-meta>September 18, 2020&nbsp;¬∑&nbsp;11 min
</div>
</header>
<div class=post-content>
<p>This year I got selected for Google Summer of Code 2020 under The Honeynet Project. This year GSoC was very special for me because I finally got selected for the organization, for which I&rsquo;ve been trying to get selected from past 2 years.</p>
<h2 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h2>
<p>I got to know about Google Summer of Code back in 2018, when I learned that my elder brother has done it 3 years in a row. He wanted me to try to get selected for any org that I like. So I started looking for projects on GSoC archives and came across the Honeynet Project org. I was interested in it because I really liked all the projects under it, projects like Snare&Tanner, Thug, etc. I think these projects attracted my attention because they have a feel of being related to the <code>Information Security</code> field.</p>
<p>In GSoC 2018 I submitted 2 proposals, one for Snare & Tanner under Honeynet Project and another one for a tool called <a href=https://github.com/xbmc/addon-check>Addon-Checker</a> under XBMC Foundation. I wasn&rsquo;t selected for Snare & Tanner that year but got selected for another project. You can read the blog post about it <a href=https://blog.mzfr.me/Gsoc-with-kodi>here</a></p>
<p>In GSoC 2019, I again applied for a project called <a href=https://github.com/cowrie/cowrie/>Cowrie</a> under Honeynet Project and wasn&rsquo;t selected. I think it was because the other applicant, who got selected had a slightly better proposal then I did.</p>
<p>In 2020, I decided to start early and make some more contributions to Snare & Tanner. Also, I spent quite some time understanding the exact work required and make a good proposal for it. The mentor of the project was very helpful from the very beginning. She reviewed my proposal twice or thrice before I made a final proposal submission on the GSoC portal</p>
<h2 id=proposed-work>Proposed Work<a hidden class=anchor aria-hidden=true href=#proposed-work>#</a></h2>
<p>The work that I proposed in my GSoC proposal was:</p>
<ol>
<li>Adding support for persistent storage for sessions, in TANNER.</li>
<li>Improving cloning and storing functionality of SNARE.</li>
<li>Small works like adding a new injection template, using async FTP library etc.</li>
</ol>
<h2 id=coding-period>Coding Period<a hidden class=anchor aria-hidden=true href=#coding-period>#</a></h2>
<p>I started to work before the official <code>coding begins</code> period, even though I didn&rsquo;t write any code but I started to discuss everything with my mentor like what we should do first, how we should start etc. Our initial idea was to start with the most important task which was to add support for PostgreSQL so the storage capability of TANNER, can become a bit more stable. In the early discussion, we decided to add PostgreSQL as an optional DB meaning users will have the option to choose between PostgreSQL and Redis DB. But later we came to the conclusion that it would be nice if we can use the combination of both the databases to improve the overall storage functionality.</p>
<h3 id=work-detail>Work Detail<a hidden class=anchor aria-hidden=true href=#work-detail>#</a></h3>
<p>Currently, in TANNER, the only way to store all the session data (analyzed and unanalyzed) was to keep it within the Redis. In TANNER the unanalyzed sessions data is the unprocessed data that is sent by the SNARE and it contains information like time of the session, user agent, etc. And analyzed sessions are those which TANNER generates after processing the unanalyzed data. The analyzed data contains information like possible owners i.e whether the sessions were created by a normal user or a crawler/tool, type of attacks, etc</p>
<p>Back in 2016 when new features were being added to TANNER, Redis was selected as the best choice because of the speed that it offers. Redis provides its speed functionality by storing data in the memory instead of keeping it in the disk. It&rsquo;s kind of similar to how a cache of any system works.</p>
<p>As the project grew we started to gather more and more data and storing everything in Redis caused it to consume a lot of memory which resulted in unexpected crashes on low spec systems.</p>
<p>Below is the diagram which explains how the SNARE & TANNER is working with the only Redis:</p>
<p><img src=https://user-images.githubusercontent.com/16623935/91330486-21dfd400-e7e7-11ea-9fc3-46531034f88e.png alt></p>
<p><strong>Disadvantages of this setup</strong></p>
<p>As mentioned above higher consumption of memory on a low spec system would result in an unexpected crash of TANNER server. Also, higher memory consumption would cause other memory issues like slowing down other applications present on the system.</p>
<p><strong>The Solution</strong></p>
<p>First, we decided that we can add support for Postgres, and then we&rsquo;ll give users the option to run tanner either with Redis or with Postgres. But later after some discussion, we decided that we&rsquo;ll use a combination of Redis and Postgres.</p>
<p>The way we decided to use them can be seen in the following diagram:</p>
<p><img src=https://user-images.githubusercontent.com/16623935/91330585-46d44700-e7e7-11ea-843b-09a01e53f236.png alt></p>
<p>As it&rsquo;s clear from the above diagram that after analysis we are storing the data in the Postgres and then we are deleting the analyzed data from Redis.</p>
<p>The advantages of using the combination of both Postgres and Redis are</p>
<ul>
<li>
<p>When TANNER receives a session from SNARE it will be able to store that session data in Redis with much higher speed.</p>
</li>
<li>
<p>Once the session is analyzed then it can be stored in persistent disk storage like Postgres.</p>
</li>
</ul>
<p><strong>Change in Data format</strong></p>
<p>One of the major advantages of having Postgres as the storage is because it gives us the power to perform queries before presenting that data to the user.</p>
<p>TANNER API is used to access the data stored in the DB. Let&rsquo;s take an example to understand how the API has changed now, we have an endpoint /snare-stats/ which returns stats like Number of attacks, total sessions, etc of a given snare instance.</p>
<p>Now in the old (Only Redis) setup, we were extracting all the data from the DB, and then we were selecting only those keys that were required for that endpoint. But now with the new (Redis+Postgres) setup, we don&rsquo;t extract all the data. What we do is we run SQL queries on the data before actually extracting the data, this saves us from unnecessary processing.</p>
<p>If you‚Äôd like to see the queries we are executing then please check out the code <a href=https://github.com/mushorg/tanner/blob/develop/tanner/api/api.py#L49>here</a></p>
<p><strong>Detail about the format</strong></p>
<p>We decided to store all the data in 4 tables named sessions, cookies, owners, paths. Below you can see the schema of all the tables:</p>
<p><img src=https://user-images.githubusercontent.com/16623935/91330802-89961f00-e7e7-11ea-95b7-ca194da79c40.png alt></p>
<p>If you&rsquo;d like to see the initial discussion about this format then check out this small <a href=https://gist.github.com/mzfr/e7cb772a6c452a12c75230430260022b>gist</a> that I made.</p>
<hr>
<p>Initially, our plan was that I&rsquo;ll spend around 2 months working on this task, and then in the last month I&rsquo;ll work on all the other tasks that I proposed but little did we know that adding support for another DB wouldn&rsquo;t be as easy as we thought.</p>
<h2 id=problems-faced>Problems Faced<a hidden class=anchor aria-hidden=true href=#problems-faced>#</a></h2>
<ul>
<li><strong>Finding and fixing a weird bug</strong>: I think this was the most frustrating bug that I came across during the whole GSoC time period.
So we have 4 tables to in our Postgres DB and out of this there is one main tabled called <code>sessions</code> and then there are other like cookies, owners, and paths. The Sessions data store a kind of reference to these tables and the bug was that when you looked at the data in the sessions table it showed there was data in the other tables but when you look at those tables separately the data was missing out.
Example:</li>
</ul>
<pre tabindex=0><code>a1894717-bf39-4f67-8493-66debde31e0b | 776edef4-ec5f-4fe0-8485-02cf9ff1f64d | 51.158.118.90 | 43972 | France  | FR           | Paris   |    75001 | Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36       | 2020-06-23 20:09:01 | 2020-06-23 20:16:23 |  9.010287049751257 |  0.11098427662381329 |           3983 |      0 |            0 |
</code></pre><p>In this, the number <code>3983</code> is the <code>accepted_path</code> value which basically means how many paths a bot/attacker tried in one session. But if we checked the count in the <code>paths</code> table it showed <code>6</code></p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>select</span> <span style=color:#66d9ef>count</span>(<span style=color:#f92672>*</span>) <span style=color:#66d9ef>from</span> paths <span style=color:#66d9ef>where</span> session_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;a1894717-bf39-4f67-8493-66debde31e0b&#39;</span>;
 <span style=color:#66d9ef>count</span>
<span style=color:#75715e>-------
</span><span style=color:#75715e></span>     <span style=color:#ae81ff>6</span>
</code></pre></div><p>The issue was that while we moved the session data between Redis(storing the initial data) and Postgres(storing analyzed sessions) some sessions were missing an <code>attack_type</code>. And all this was a fault of a small function called <code>set_attack_type</code> and it was because we were doing some URL encoding while taking information from SNARE to Redis but wasn&rsquo;t doing the same after analyzing the data and sending it to POSTGRES.</p>
<ul>
<li><strong>Support multiple filters in API</strong>: The API as well as the Web application needed to support the multiple filters same time. So say if you want all the sessions from two different IP addresses the API call would look like:</li>
</ul>
<pre tabindex=0><code>&lt;SNARE-ID&gt;/sessions?filters=ip:127.0.0.1 ip:192.1.1.1
</code></pre><p>Now this looks easy and a lot of <code>python</code> devs might see this and be like <code>oh you can split it on space and then it's all easy</code> but it wasn&rsquo;t that easy. I had to make sure that no unknown filters were passed and the biggest issue was that I had to generate a SQL query based on all the filters so it(API) can get the exact data out of the DB.</p>
<ul>
<li>
<p><strong>Testing</strong>: I think this is one of the most important things that I have learned this GSoC. Testing your code is very important and I kind of already knew this but I wasn&rsquo;t doing this practically. But a lot of times I felt that I could have caught certain bugs right when they appeared if I had written the test cases for the newly written code right after finishing the code.
The problem that I faced during the testing phase exactly &ldquo;while writing them&rdquo; but it was while running them. Once Pytest would finish running the tests it would show warnings about &ldquo;unclosed connection&rdquo;. Fixing this was a bit difficult because most of the libraries used in this project are async and I was quite confused with the working. The most difficult part was that sometimes when I locally ran the tests there were no warnings but in the Travis logs, we could see ike 5-10 warnings so it was hard testing it locally.</p>
</li>
<li>
<p><strong>Shift to SQLAlchemy</strong>: This wasn&rsquo;t the problem but I am writing about this because this definitely took some of our time. So in the starting I and my mentor thought that using raw SQL queries wouldn&rsquo;t be as such of an issue. But once I made some intial changes we both felt that the code was getting a <code>bit dirty</code> and hard to understand. So we decided it would be better if we use SQLAlchemy, since this ORM would provide lot of functionality which would keep our code clean and simple.</p>
</li>
</ul>
<h2 id=completed-work>Completed Work<a hidden class=anchor aria-hidden=true href=#completed-work>#</a></h2>
<p>So out of the suggested task, I was able to finish the task of adding support for persistent storage and the other small task like adding new template injections or updating the FTP support to use the async library. Even though I had completed the PostgreSQL task in around 2.5 months and could have tried to do another big task but then my mentor suggested that instead of trying to have a lot of new features, it would be better to improve the existing features that we have. That is why we decided not to go ahead with &ldquo;changing the snare storage and cloning functionality&rdquo; and decided to do other small tasks.</p>
<h2 id=lesson-learned>Lesson Learned<a hidden class=anchor aria-hidden=true href=#lesson-learned>#</a></h2>
<ol>
<li>
<p>It&rsquo;s very important to test your code. You can use whatever automated tools possible to try and test them. Also once you feel that you are done adding a new feature, write the tests for the code right away.</p>
</li>
<li>
<p>During the Proposal making phase I had written things like &ldquo;Take test coverage to 100%&rdquo; and &ldquo;finish PostgreSQL integration in 2 weeks&rdquo; but in reality, the DB integration took around ~2.5 months and the test coverage is at around 78% now üòÖ. So after the GSoC I have realized that it&rsquo;s better to have few tasks in your timeline with clear deliverables, goals, etc rather than trying to add loads of tas without thinking them through.</p>
</li>
<li>
<p>Sometimes everything is right in front of you you just need to take a good look. This happened with me multiple times, the bug was right in front of me but I still had to ask my mentor about it.</p>
</li>
<li>
<p>Before this I had never worked on any DB related work. I mean I did studied DBMS in my 3rd year of college but never got a chance to work on a real world project so I learned a lot about PostgreSQL, Redis, SQLAlchemy etc.</p>
</li>
</ol>
<h2 id=final-thoughts>Final thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2>
<p>I had planned that even after the GSoC ends I&rsquo;ll continue to work on the project but due to this year being the final year of my degree my life has changed a lot. Campus placement has started in my college so now I have to prepare for the tests and interviews. Along with that, I have to prepare my thesis and a major project. So right now I am not sure when I&rsquo;ll get back to contributing to the project.</p>
<p>In the end, I just want to thank the Honeynet Project org and my mentor for seeing the potential in me and selecting me for this year GSoC. Also other special thanks to the mentor for being so helpful and patient with me.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://blog.mzfr.me/tags/gsoc>GSoC</a></li>
</ul>
</footer>
</article>
</main><footer class=footer>
<span>&copy; 2022 <a href=https://blog.mzfr.me>mzfr's Blog</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span>
</footer>
<button class=top-link id=top-link type=button aria-label="go to top" title="Go to Top" accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg>
</button>
<script defer src=https://blog.mzfr.me/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))};var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.onclick=function(){document.body.scrollTop=0,document.documentElement.scrollTop=0,window.location.hash=''};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>